# awesome-text-only-training
The project is used to store text-only training related papers
## papers
### Lite Version
#### <br/>> **2024**

* [**AAAI**]  Mining Fine-Grained Image-Text Alignment for Zero-Shot Captioning via Text-Only Training    [[paper]](https://papers.cool/arxiv/2401.02347)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>

* [**ACM**]  TOMGPT: Reliable Text-Only Training Approach for Cost-Effective Multi-modal Large Language Model[[paper]](https://dl.acm.org/doi/abs/10.1145/3654674)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>

* [**IJCV**]  Learning to Prompt with Text Only Supervision for Vision-Language Models[[paper]](https://papers.cool/arxiv/2401.02418)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>
* [**arxiv**]  Learning to Prompt with Text Only Supervision for Vision-Language Models[[paper]](https://papers.cool/arxiv/2401.02418)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>
* [**arxiv**]  Text Data-Centric Image Captioning with Interactive Prompts[[paper]](https://papers.cool/arxiv/2403.19193)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>
* [**arxiv**]  MeaCap: Memory-Augmented Zero-shot Image Captioning[[paper]](https://www.semanticscholar.org/paper/70faf1731707ddb329877031a00d4b262902ba3c)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>
* [**arxiv**]  ArcSin: Adaptive ranged cosine Similarity injected noise for Language-Driven Visual Tasks    [[paper]](https://arxiv.org/abs/2402.17298)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>

#### <br/>> **2023**
* [**arxiv**]  Improved Factorized Neural Transducer Model For text-only Domain Adaptation[[paper]](2309.09524)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>
* [**AAAI**]  Improving Cross-modal Alignment with Synthetic Pairs for Text-only Image Captioning[[paper]](https://papers.cool/arxiv/2312.08865)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>
* [**ACM**]  Text-Only Training for Visual Storytelling[[paper]](https://papers.cool/arxiv/2308.08881)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>

* [**NeurlPS**]  LOVM:Language-Only Vision Model Selection[[paper]](https://papers.cool/arxiv/2306.08893)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>
* [**IJCAI**]  From Association to Generation: Text-only Captioning by Unsupervised Cross-modal Mapping[[paper]](https://www.semanticscholar.org/paper/f7d9e553398afe0d363130e1872778761de8e917)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>
* [**ICLR**]  Decoding CLIP Latents for Zero-Shot Captioning via Text-Only Training[[paper]](https://papers.cool/arxiv/2303.03032)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>
* [**DCASE**]  Weakly-supervised Automated Audio Captioning via text only training[[paper]](https://papers.cool/arxiv/2309.12242)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>
* [**ACM**]  CgT-GAN: CLIP-guided Text GAN for Image Captioning[[paper]](https://arxiv.org/abs/2308.12045)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>


#### <br/>> **2022**
* [**EMNLP**]  Text-Only Training for Image Captioning using Noise-Injected CLIP[[paper]](https://papers.cool/arxiv/2211.00575)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>

* [**ICCV**]  I Can't Believe There's No Images! Learning Visual Tasks Using only Language Supervision[[paper]](https://papers.cool/arxiv/2211.09778)  [[code]](https://github.com/iOPENCap/Graph-reproduction/edit/main/README.md)<br/>

#### <br/>> **2021**

* [**CVPR**]  LAFITE: Towards Language-Free Training for Text-to-Image Generation[[paper]](https://arxiv.org/abs/2111.13792)  [[code]](https://github.com/drboog/Lafite)<br/>
